import React, { useState, useRef, useEffect } from 'react';
import { VideoMode, Resolution, AspectRatio, GenerationHistory, UserProfile } from '../types';
import { generateVeoVideo } from "../services/veo-client";
import { getUserPackage } from "../services/license";
import {
  DIRECTOR_MODE_INSTRUCTION,
  LINK_ANALYSIS_INSTRUCTION,
  SEAMLESS_FLOW_INSTRUCTION,
  IMAGE_GEN_INSTRUCTION,
  CONSISTENCY_IMAGE_GEN_INSTRUCTION
} from '../constants';
import { GoogleGenAI } from "@google/genai";

interface VideoGeneratorProps {
  onGenerated: (item: GenerationHistory) => void;
  history: GenerationHistory[];
  onOpenPricing: () => void;
  profile: UserProfile;
  onKeyError: () => void;
  analyzedScript: string;
  setAnalyzedScript: (s: string) => void;
  directorScript: string;
  setDirectorScript: (s: string) => void;
  seamlessScript: string;
  setSeamlessScript: (s: string) => void;
  targetLink: string;
  setTargetLink: (l: string) => void;
  batchResults: {prompt: string, url: string}[];
  setBatchResults: (res: {prompt: string, url: string}[]) => void;
  generatedImageUrl: string | null;
  setGeneratedImageUrl: (url: string | null) => void;
}

enum ToolMode {
  NONE = 'NONE',
  DIRECTOR = 'DIRECTOR',
  LINK_ANALYSER = 'LINK_ANALYSER',
  SEAMLESS_FLOW = 'SEAMLESS_FLOW',
  IMAGE_GEN = 'IMAGE_GEN',
  BATCH_IMAGE_GEN = 'BATCH_IMAGE_GEN'
}

export const VideoGenerator: React.FC<VideoGeneratorProps> = ({
  onGenerated, history, onOpenPricing, profile, onKeyError,
  analyzedScript, setAnalyzedScript, directorScript, setDirectorScript,
  seamlessScript, setSeamlessScript, targetLink, setTargetLink,
  batchResults, setBatchResults, generatedImageUrl, setGeneratedImageUrl
}) => {
  const [mode, setMode] = useState<VideoMode>(VideoMode.TEXT_TO_VIDEO);
  const [toolMode, setToolMode] = useState<ToolMode>(ToolMode.NONE);
  const [concurrentRenderCount, setConcurrentRenderCount] = useState<0 | 3 | 5>(0);
  const [isFullVideoRendering, setIsFullVideoRendering] = useState(false);
  const [outputLanguage, setOutputLanguage] = useState<'EN' | 'VN'>('EN');
  const [aspectRatio, setAspectRatio] = useState<AspectRatio>(AspectRatio.LANDSCAPE);
  const [resolution, setResolution] = useState<Resolution>(Resolution.R720P);

  const [selectedTaskIds, setSelectedTaskIds] = useState<Set<string>>(new Set());
  const [editingTaskId, setEditingTaskId] = useState<string | null>(null);
  const [editPromptValue, setEditPromptValue] = useState("");

  // Countdown states
  const [countdown, setCountdown] = useState(20);
  const countdownIntervalRef = useRef<any>(null);

  // Batch Image Gen state
  const [batchPrompts, setBatchPrompts] = useState("");
  const [refImage, setRefImage] = useState<string | null>(() => localStorage.getItem('veopro_ref_image'));

  // STATE M·ªöI CHO KEY FREE
  const [customUserKey, setCustomUserKey] = useState<string>(() => localStorage.getItem('userCustomApiKey') || '');

  useEffect(() => {
    if (refImage) localStorage.setItem('veopro_ref_image', refImage);
    else localStorage.removeItem('veopro_ref_image');
  }, [refImage]);

  // L∆∞u key free
  useEffect(() => {
    if (customUserKey.trim()) localStorage.setItem('userCustomApiKey', customUserKey.trim());
    else localStorage.removeItem('userCustomApiKey');
  }, [customUserKey]);

  const [modePrompts, setModePrompts] = useState<Record<VideoMode, string>>(() => {
    try {
      const saved = localStorage.getItem('veopro_mode_prompts');
      return saved ? JSON.parse(saved) : {
        [VideoMode.TEXT_TO_VIDEO]: '', [VideoMode.IMAGE_TO_VIDEO]: '', [VideoMode.INTERPOLATION]: '', [VideoMode.CONSISTENCY]: ''
      };
    } catch { return { [VideoMode.TEXT_TO_VIDEO]: '', [VideoMode.IMAGE_TO_VIDEO]: '', [VideoMode.INTERPOLATION]: '', [VideoMode.CONSISTENCY]: '' }; }
  });

  const [modeImages, setModeImages] = useState<Record<VideoMode, {url: string, name: string}[]>>(() => {
    try {
      const saved = localStorage.getItem('veopro_mode_images');
      const parsed = saved ? JSON.parse(saved) : {};
      return {
        [VideoMode.TEXT_TO_VIDEO]: parsed[VideoMode.TEXT_TO_VIDEO] || [],
        [VideoMode.IMAGE_TO_VIDEO]: parsed[VideoMode.IMAGE_TO_VIDEO] || [],
        [VideoMode.INTERPOLATION]: parsed[VideoMode.INTERPOLATION] || [],
        [VideoMode.CONSISTENCY]: parsed[VideoMode.CONSISTENCY] || [],
      };
    } catch {
      return { [VideoMode.TEXT_TO_VIDEO]: [], [VideoMode.IMAGE_TO_VIDEO]: [], [VideoMode.INTERPOLATION]: [], [VideoMode.CONSISTENCY]: [] };
    }
  });

  useEffect(() => { 
    try { localStorage.setItem('veopro_mode_prompts', JSON.stringify(modePrompts)); } catch(e) {}
  }, [modePrompts]);
  
  useEffect(() => { 
    try { localStorage.setItem('veopro_mode_images', JSON.stringify(modeImages)); } catch(e) {}
  }, [modeImages]);

  const [concurrentPrompts, setConcurrentPrompts] = useState<string[]>(() => {
    try {
      const saved = localStorage.getItem('veopro_concurrent_prompts');
      return saved ? JSON.parse(saved) : ['', '', '', '', ''];
    } catch { return ['', '', '', '', '']; }
  });

  useEffect(() => {
    try { localStorage.setItem('veopro_concurrent_prompts', JSON.stringify(concurrentPrompts)); } catch(e) {}
  }, [concurrentPrompts]);

  const [isGenerating, setIsGenerating] = useState(false);
  const isStoppingRef = useRef(false);
  const [activeTasks, setActiveTasks] = useState<GenerationHistory[]>([]);
  const [directorForm, setDirectorForm] = useState({ genre: 'H√†nh ƒë·ªông', plot: '', mainChar: '' });
  const [seamlessForm, setSeamlessForm] = useState({ script: '', dna: '' });
  const [toolPromptCount, setToolPromptCount] = useState('10');
  const fileInputRef = useRef<HTMLInputElement>(null);
  const refImageInputRef = useRef<HTMLInputElement>(null);
  const specificSlotRef = useRef<{ index: number; subIndex?: number } | null>(null);
  const [showZaloQR, setShowZaloQR] = useState(false);

  const currentImages = modeImages[mode] || [];
  const currentPromptText = modePrompts[mode] || '';

  const updatePromptForMode = (newText: string) => setModePrompts(prev => ({ ...prev, [mode]: newText }));

  const startCountdown = () => {
    setCountdown(20);
    if (countdownIntervalRef.current) clearInterval(countdownIntervalRef.current);
    countdownIntervalRef.current = setInterval(() => {
      setCountdown(prev => (prev <= 1 ? 20 : prev - 1));
    }, 1000);
  };

  const stopCountdown = () => {
    if (countdownIntervalRef.current) clearInterval(countdownIntervalRef.current);
    setCountdown(20);
  };

  const toggleSelectTask = (taskId: string) => {
    setSelectedTaskIds(prev => {
      const next = new Set(prev);
      if (next.has(taskId)) next.delete(taskId);
      else next.add(taskId);
      return next;
    });
  };

  const startEditTask = (task: GenerationHistory) => {
    setEditingTaskId(task.id);
    setEditPromptValue(task.prompt);
  };

  const saveEditTask = (taskId: string) => {
    setActiveTasks(prev => prev.map(t => t.id === taskId ? { ...t, prompt: editPromptValue } : t));
    setEditingTaskId(null);
  };

  const deleteTask = (taskId: string) => {
    setActiveTasks(prev => prev.filter(t => t.id !== taskId));
    setSelectedTaskIds(prev => {
      const next = new Set(prev);
      next.delete(taskId);
      return next;
    });
  };

  const downloadVideoFile = async (url: string, filename: string) => {
    if (!url) return;
    try {
      const response = await fetch(url);
      const blob = await response.blob();
      const a = document.createElement('a');
      a.href = URL.createObjectURL(blob);
      a.download = `${filename}.mp4`;
      document.body.appendChild(a);
      a.click();
      document.body.removeChild(a);
    } catch (err) {
      console.error("Download failed:", err);
    }
  };

  // H√ÄM CH√çNH S·ª¨A ƒê·∫¶Y ƒê·ª¶
  const runGenerationTask = async (prompt: string, index: number, total: number, laneId: string = '', prevVideoRef?: any, imagesSnapshot?: {url: string, name: string}[], modeSnapshot?: VideoMode) => {
    if (isStoppingRef.current) return null;
   
    const activeMode = modeSnapshot || mode;
    const activeImages = imagesSnapshot || currentImages;
   
    const taskId = `vpro-${Date.now()}-${laneId}-${index}`;
    const task: GenerationHistory = {
      id: taskId,
      url: '',
      prompt,
      timestamp: Date.now(),
      mode: activeMode,
      progress: 5,
      status: `${laneId ? `Lu·ªìng ${laneId}: ` : ''}ƒêang t·∫°o...`
    };
   
    setActiveTasks(prev => [task, ...prev]);
   
    try {
      let reqImages: string[] = [];
      if (!prevVideoRef) {
        if (activeMode === VideoMode.IMAGE_TO_VIDEO) {
          reqImages = [activeImages[index]?.url].filter(url => !!url);
        } else if (activeMode === VideoMode.INTERPOLATION) {
          reqImages = [activeImages[index*2]?.url, activeImages[index*2+1]?.url].filter(url => !!url);
        } else if (activeMode === VideoMode.CONSISTENCY) {
          reqImages = activeImages.map(img => img.url).filter(url => !!url);
        }
      }
     
      // LOGIC G√ìI USER M·ªöI
      const userPkg = getUserPackage();
      let customKey: string | undefined = undefined;
      if (userPkg === "free") {
        customKey = customUserKey.trim();
        if (!customKey) {
          throw new Error("G√≥i mi·ªÖn ph√≠: Vui l√≤ng nh·∫≠p Google API Key ri√™ng!");
        }
      }
     
      const result = await generateVeoVideo({
        mode: activeMode, 
        prompt, 
        resolution, 
        aspectRatio, 
        images: reqImages,
        previousVideo: prevVideoRef, 
        onProgress: (msg) => {
          if (isStoppingRef.current) return;
          setActiveTasks(cur => cur.map(t => t.id === taskId ? { ...t, status: `${laneId ? `Lu·ªìng ${laneId}: ` : ''}${msg}`, progress: Math.min((t.progress || 5) + 3, 99) } : t));
        },
        userPackage: userPkg,
        customKey,
      });
     
      if (isStoppingRef.current) return null;
      const completed = { ...task, url: result.finalUrl, status: 'Ho√†n th√†nh', progress: 100 };
      onGenerated(completed);
      setActiveTasks(cur => cur.map(t => t.id === taskId ? completed : t));
      return result.videoRef;
    } catch (err: any) {
      setActiveTasks(cur => cur.map(t => t.id === taskId ? { ...t, status: 'L·ªói: ' + (err.message || 'Kh√¥ng x√°c ƒë·ªãnh'), progress: 0 } : t));
      if (err.message?.includes("Key") || err.message?.includes("quota")) onKeyError();
      return null;
    }
  };

  const handleRunFullVideo = async () => {
    const prompts = seamlessScript.split('\n').map(p => p.trim()).filter(p => p !== '');
    if (prompts.length === 0) { alert("Vui l√≤ng nh·∫≠p k·ªãch b·∫£n n·ªëi m·∫°ch."); return; }
   
    setIsFullVideoRendering(true); setIsGenerating(true); isStoppingRef.current = false;
    startCountdown();
   
    const imagesSnapshot = JSON.parse(JSON.stringify(currentImages));
    const modeSnapshot = mode;
   
    let lastVideoRef = null;
    for (let i = 0; i < prompts.length; i++) {
      if (isStoppingRef.current) break;
      lastVideoRef = await runGenerationTask(prompts[i], i, prompts.length, 'CinemaFlow', lastVideoRef, imagesSnapshot, modeSnapshot);
    }
    setIsFullVideoRendering(false); setIsGenerating(false);
    stopCountdown();
  };

  const handleGenerate = async () => {
    setIsGenerating(true); isStoppingRef.current = false;
    startCountdown();
   
    const imagesSnapshot = JSON.parse(JSON.stringify(currentImages));
    const modeSnapshot = mode;
   
    try {
      if (concurrentRenderCount > 0) {
        const activePrompts = concurrentPrompts.slice(0, concurrentRenderCount).filter(p => p.trim() !== '');
        if (activePrompts.length === 0) { alert("Vui l√≤ng nh·∫≠p k·ªãch b·∫£n cho c√°c lu·ªìng."); setIsGenerating(false); return; }
       
        await Promise.all(activePrompts.map((p, i) =>
          runGenerationTask(p, i, activePrompts.length, (i + 1).toString(), undefined, imagesSnapshot, modeSnapshot)
        ));
      } else {
        const prompts = currentPromptText.split('\n').map(p => p.trim()).filter(p => p !== '');
        if (prompts.length === 0) { alert("Vui l√≤ng nh·∫≠p k·ªãch b·∫£n."); setIsGenerating(false); return; }
        for (let i = 0; i < prompts.length; i++) {
          if (isStoppingRef.current) break;
          await runGenerationTask(prompts[i], i, prompts.length, '', undefined, imagesSnapshot, modeSnapshot);
        }
      }
    } finally { setIsGenerating(false); stopCountdown(); }
  };

  const handleStop = () => {
    isStoppingRef.current = true;
    setIsGenerating(false);
    setIsFullVideoRendering(false);
    stopCountdown();
    alert("üõë D·ª™NG KH·∫®N C·∫§P: H·ªá th·ªëng ƒë√£ ng·∫Øt to√†n b·ªô t√°c v·ª• ƒëang ch·∫°y.");
  };

  const handleFileChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    const files = Array.from(e.target.files || []) as File[];
    if (files.length === 0) return;
   
    const activeMode = mode;
    const slot = specificSlotRef.current;
   
    files.forEach((file, fIdx) => {
      const reader = new FileReader();
      reader.onload = (event) => {
        const base64 = event.target?.result as string;
        if (base64) {
          setModeImages(prev => {
            const currentList = [...(prev[activeMode] || [])];
            if (slot) {
              let targetIdx = slot.index;
              if (activeMode === VideoMode.INTERPOLATION && slot.subIndex !== undefined) {
                targetIdx = slot.index * 2 + slot.subIndex;
              }
              const finalIdx = targetIdx + fIdx;
              while (currentList.length <= finalIdx) currentList.push({ url: '', name: '' });
              currentList[finalIdx] = { url: base64, name: file.name.split('.')[0] };
            } else {
              currentList.push({ url: base64, name: file.name.split('.')[0] });
            }
            return { ...prev, [activeMode]: currentList };
          });
        }
      };
      reader.readAsDataURL(file);
    });
   
    specificSlotRef.current = null;
    if (fileInputRef.current) fileInputRef.current.value = '';
  };

  const handleRefImageChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (file) {
      const reader = new FileReader();
      reader.onload = (event) => setRefImage(event.target?.result as string);
      reader.readAsDataURL(file);
    }
  };

  const handleBatchImageGen = async () => {
    if (!batchPrompts.trim() || !refImage) { alert("Vui l√≤ng nh·∫≠p k·ªãch b·∫£n v√† t·∫£i l√™n ·∫£nh ƒë·∫ßu."); return; }
    setIsGenerating(true); isStoppingRef.current = false;
    startCountdown();
   
    const lines = batchPrompts.split('\n').map(l => l.trim()).filter(l => l !== '');
   
    try {
      const apiKey = customUserKey.trim() || import.meta.env.VITE_GOOGLE_KEY_PRO1 || '';
      const ai = new GoogleGenAI({ apiKey });
     
      const getRawBase64 = (b64: string) => b64.includes(',') ? b64.split(',')[1] : b64;
      for (const line of lines) {
        if (isStoppingRef.current) break;
        const response = await ai.models.generateContent({
          model: 'gemini-3-pro-image-preview',
          contents: {
            parts: [
              { inlineData: { data: getRawBase64(refImage), mimeType: 'image/png' } },
              { text: `Current scene prompt: ${line}` }
            ]
          },
          config: {
            systemInstruction: CONSISTENCY_IMAGE_GEN_INSTRUCTION,
            imageConfig: {
              aspectRatio: aspectRatio === AspectRatio.LANDSCAPE ? "16:9" : "9:16",
              imageSize: "1K"
            }
          }
        });
        if (isStoppingRef.current) break;
        for (const part of response.candidates?.[0]?.content?.parts || []) {
          if (part.inlineData) {
            const url = `data:image/png;base64,${part.inlineData.data}`;
            setBatchResults([...batchResults, { prompt: line, url }]);
            break;
          }
        }
      }
    } catch (err) { alert("L·ªói render ·∫£nh."); } finally { setIsGenerating(false); stopCountdown(); }
  };

  const handleToolGenerate = async (tMode: ToolMode) => {
    setIsGenerating(true); isStoppingRef.current = false;
    startCountdown();
    try {
      const apiKey = customUserKey.trim() || import.meta.env.VITE_GOOGLE_KEY_PRO1 || '';
      const ai = new GoogleGenAI({ apiKey });
      const langText = outputLanguage === 'EN' ? 'Anh M·ªπ (English US)' : 'Vi·ªát Nam (Vietnamese)';
      if (tMode === ToolMode.IMAGE_GEN) {
        const prompt = `Script/Context: ${seamlessForm.script}. Character DNA/Description: ${seamlessForm.dna}. Genre/Style: ${directorForm.genre}. Ng√¥n ng·ªØ y√™u c·∫ßu: ${langText}.`;
        const response = await ai.models.generateContent({
          model: 'gemini-3-pro-image-preview',
          contents: { parts: [{ text: prompt }] },
          config: {
            systemInstruction: IMAGE_GEN_INSTRUCTION,
            imageConfig: {
              aspectRatio: aspectRatio === AspectRatio.LANDSCAPE ? "16:9" : aspectRatio === AspectRatio.PORTRAIT ? "9:16" : "1:1",
              imageSize: "1K"
            }
          }
        });
       
        if (isStoppingRef.current) return;
        for (const part of response.candidates?.[0]?.content?.parts || []) {
          if (part.inlineData) {
            setGeneratedImageUrl(`data:image/png;base64,${part.inlineData.data}`);
            break;
          }
        }
      } else {
        let instruction = '', content = '';
        if (tMode === ToolMode.DIRECTOR) { instruction = DIRECTOR_MODE_INSTRUCTION; content = `Th·ªÉ lo·∫°i: ${directorForm.genre}. Plot: ${directorForm.plot}. DNA: ${directorForm.mainChar}. S·ªë c·∫£nh: ${toolPromptCount}. Ng√¥n ng·ªØ y√™u c·∫ßu: ${langText}.`; }
        else if (tMode === ToolMode.LINK_ANALYSER) { instruction = LINK_ANALYSIS_INSTRUCTION; content = `Youtube: ${targetLink}. C·∫£nh: ${toolPromptCount}. Ng√¥n ng·ªØ y√™u c·∫ßu: ${langText}.`; }
        else if (tMode === ToolMode.SEAMLESS_FLOW) { instruction = SEAMLESS_FLOW_INSTRUCTION; content = `K·ªãch b·∫£n: ${seamlessForm.script}. DNA: ${seamlessForm.dna}. C·∫£nh: ${toolPromptCount}. Ng√¥n ng·ªØ y√™u c·∫ßu: ${langText}.`; }
       
        const response = await ai.models.generateContent({ model: 'gemini-3-pro-preview', contents: content, config: { systemInstruction: instruction } });
       
        if (isStoppingRef.current) return;
       
        const text = response.text || '';
        if (tMode === ToolMode.DIRECTOR) setDirectorScript(text); else if (tMode === ToolMode.LINK_ANALYSER) setAnalyzedScript(text); else if (tMode === ToolMode.SEAMLESS_FLOW) setSeamlessScript(text);
        const extracted = text.match(/\[.*?\]/g); if (extracted) updatePromptForMode(extracted.map(p => p.slice(1, -1)).join('\n'));
      }
    } catch (err) { alert("L·ªói AI Studio."); } finally { setIsGenerating(false); stopCountdown(); }
  };

  const renderScriptView = (text: string, title: string) => (
    <div className="flex-1 bg-white p-4 font-serif leading-relaxed text-slate-900 overflow-y-auto custom-scrollbar shadow-inner min-h-0 relative">
      <div className="sticky top-0 right-0 z-30 flex justify-end mb-2">
        <button onClick={() => { navigator.clipboard.writeText(text); alert("Copy xong!"); }} className="bg-indigo-600 text-white px-2 py-1 rounded-lg text-[8px] font-black uppercase active:scale-95">üìã Copy</button>
      </div>
      <h3 className="text-base font-black text-center mb-3 uppercase underline decoration-2 underline-offset-4 decoration-indigo-500 italic">{title}</h3>
      {toolMode === ToolMode.IMAGE_GEN && generatedImageUrl ? (
        <div className="flex flex-col items-center space-y-4">
          <img src={generatedImageUrl} className="w-full rounded-2xl shadow-2xl border-4 border-slate-100" alt="Generated Cinematic" />
          <button onClick={() => {
             const link = document.createElement('a');
             link.href = generatedImageUrl;
             link.download = `cinematic_dna_${Date.now()}.png`;
             link.click();
          }} className="bg-emerald-600 text-white px-4 py-2 rounded-xl text-[10px] font-black uppercase shadow-lg active:scale-95">üì• T·∫£i ·∫¢nh</button>
        </div>
      ) : (
        <div className="space-y-3">{text ? text.split('\n').map((line, idx) => (<p key={idx} className={line.startsWith('[') ? 'bg-indigo-50 p-2 rounded-xl border border-indigo-100 italic text-[10px]' : 'text-slate-700 text-[10px]'}>{line}</p>)) : <div className="h-full flex items-center justify-center text-slate-300 italic font-black text-xs opacity-30">Studio Output...</div>}</div>
      )}
    </div>
  );

  return (
    <div className="flex flex-col flex-1 bg-[#f8fafc] p-2 overflow-hidden font-sans text-slate-800 h-full max-h-full">
      {/* PH·∫¶N M·ªöI: HI·ªÇN TH·ªä G√ìI + INPUT KEY */}
      <div className="mb-4 p-4 bg-white rounded-3xl border-4 border-slate-200 shadow-2xl">
        {getUserPackage() === "free" ? (
          <div className="p-6 bg-yellow-50 border-4 border-yellow-300 rounded-2xl">
            <label className="block text-lg font-black text-yellow-800 mb-3 uppercase">NH·∫¨P KEY RI√äNG (G√≥i mi·ªÖn ph√≠)</label>
            <input
              type="text"
              placeholder="D√°n Google API Key c·ªßa b·∫°n v√†o ƒë√¢y"
              className="w-full px-6 py-4 border-4 border-yellow-200 rounded-2xl text-lg font-bold focus:border-yellow-500 outline-none bg-white"
              value={customUserKey}
              onChange={(e) => setCustomUserKey(e.target.value)}
            />
            <p className="text-sm text-yellow-700 mt-3 font-bold">T·∫°o key mi·ªÖn ph√≠ t·∫°i ai.google.dev (g√≥i free gi·ªõi h·∫°n 1 lu·ªìng, 720p)</p>
          </div>
        ) : (
          <div className="p-6 bg-emerald-50 border-4 border-emerald-300 rounded-2xl text-center">
            <p className="text-2xl font-black text-emerald-600 uppercase">
              ƒêang d√πng g√≥i {getUserPackage() === "pro9" ? "Chuy√™n Nghi·ªáp 9" : "Chuy√™n Nghi·ªáp 1"}
            </p>
            <p className="text-lg font-bold text-emerald-700 mt-2">Full t·ªëc ƒë·ªô, ch·∫•t l∆∞·ª£ng cao, nhi·ªÅu lu·ªìng song song</p>
          </div>
        )}
      </div>

      {/* HEADER SECTION - gi·ªØ nguy√™n */}
      <div className="flex flex-col md:flex-row justify-between items-center mb-2 px-4 bg-white py-2 rounded-[1.5rem] md:rounded-[2.5rem] border border-slate-200 shadow-xl flex-shrink-0 gap-2">
        <div className="flex flex-wrap items-center justify-center gap-2">
          <button onClick={() => { setToolMode(ToolMode.DIRECTOR); setConcurrentRenderCount(0); }} className={`px-4 py-2 rounded-full text-[9px] font-black uppercase transition-all border-2 active:scale-95 ${toolMode === ToolMode.DIRECTOR ? 'bg-indigo-600 text-white border-indigo-700' : 'bg-white text-indigo-600 border-slate-100'}`}>üé¨ ƒê·∫°o di·ªÖn Hollywood</button>
          <button onClick={() => { setToolMode(ToolMode.LINK_ANALYSER); setConcurrentRenderCount(0); }} className={`px-4 py-2 rounded-full text-[9px] font-black uppercase transition-all border-2 active:scale-95 ${toolMode === ToolMode.LINK_ANALYSER ? 'bg-blue-600 text-white border-blue-700' : 'bg-white text-blue-600 border-slate-100'}`}>üîó Ph√¢n t√≠ch Link Youtube</button>
          <button onClick={() => { setToolMode(ToolMode.SEAMLESS_FLOW); setConcurrentRenderCount(0); }} className={`px-4 py-2 rounded-full text-[9px] font-black uppercase transition-all border-2 active:scale-95 ${toolMode === ToolMode.SEAMLESS_FLOW ? 'bg-emerald-600 text-white border-emerald-700' : 'bg-white text-emerald-600 border-slate-100'}`}>üîó Prompt li·ªÅn m·∫°ch</button>
          <button onClick={() => { setToolMode(ToolMode.BATCH_IMAGE_GEN); setBatchPrompts(seamlessScript || analyzedScript || directorScript || ""); }} className={`px-4 py-2 rounded-full text-[9px] font-black uppercase transition-all border-2 active:scale-95 bg-white text-cyan-600 border-cyan-100 hover:border-cyan-400 hover:bg-cyan-50 shadow-sm`}>üñºÔ∏è T·∫°o ·∫£nh cu·ªëi cho m·ªói prompt</button>
          <button onClick={() => { setToolMode(ToolMode.IMAGE_GEN); setConcurrentRenderCount(0); }} className={`px-4 py-2 rounded-full text-[9px] font-black uppercase transition-all border-2 active:scale-95 ${toolMode === ToolMode.IMAGE_GEN ? 'bg-amber-600 text-white border-amber-700' : 'bg-white text-amber-600 border-slate-100'}`}>üé® T·∫°o ·∫£nh t·ª´ K·ªãch b·∫£n v√† DNA</button>
        </div>
        <div className="flex items-center gap-2">
           <button onClick={() => setShowZaloQR(true)} className="flex items-center space-x-2 text-[9px] text-blue-600 font-black bg-white px-3 py-1.5 rounded-full border-2 border-blue-100 shadow-lg active:scale-95 transition-all hover:border-blue-200"><span className="bg-blue-600 text-white rounded-full px-2 py-0.5 text-[7px]">H·ªó tr·ª£</span><span>K·ª∏ THU·∫¨T AI</span></button>
        </div>
      </div>

      {/* PH·∫¶N C√íN L·∫†I GI·ªÆ NGUY√äN 100% CODE G·ªêC C·ª¶A ANH (flex lg:flex-row, left column, right column, footer, modal, input file...) */}
      <div className="flex flex-col lg:flex-row flex-1 gap-2 min-h-0 overflow-hidden">
        {/* LEFT COLUMN - gi·ªØ nguy√™n */}
        <div className="flex-1 flex flex-col min-w-0 h-full overflow-hidden">
          <div className="bg-white border-2 border-slate-200 rounded-[1.5rem] md:rounded-[2.5rem] shadow-2xl flex flex-col flex-1 overflow-hidden relative border-t-[6px] border-t-indigo-600 min-h-0">
            {/* ... to√†n b·ªô code left column c≈© c·ªßa anh ... */}
          </div>
        </div>

        {/* RIGHT COLUMN - gi·ªØ nguy√™n */}
        <div className="flex-1 lg:flex-[0.75] flex flex-col min-w-0 h-full overflow-hidden">
          <div className="bg-white border-2 border-slate-200 rounded-[1.5rem] md:rounded-[2.5rem] shadow-2xl flex flex-col flex-1 border-t-[6px] border-t-blue-600 overflow-hidden min-h-0 relative">
            {/* ... to√†n b·ªô code right column c≈© c·ªßa anh ... */}
          </div>
        </div>
      </div>

      {/* MODAL ZALO v√† INPUT FILE - gi·ªØ nguy√™n */}
      {showZaloQR && (
        <div className="fixed inset-0 bg-black/80 backdrop-blur-xl flex items-center justify-center p-4 z-[500] animate-in fade-in duration-300">
          {/* ... code modal c≈© ... */}
        </div>
      )}

      <input type="file" ref={fileInputRef} onChange={handleFileChange} multiple hidden accept="image/*" />
      <input type="file" ref={refImageInputRef} onChange={handleRefImageChange} hidden accept="image/*" />
    </div>
  );
};      </div>

      {/* MODAL ZALO v√† INPUT FILE - gi·ªØ nguy√™n */}
      {showZaloQR && (
        <div className="fixed inset-0 bg-black/80 backdrop-blur-xl flex items-center justify-center p-4 z-[500] animate-in fade-in duration-300">
          {/* ... code modal c≈© ... */}
        </div>
      )}

      <input type="file" ref={fileInputRef} onChange={handleFileChange} multiple hidden accept="image/*" />
      <input type="file" ref={refImageInputRef} onChange={handleRefImageChange} hidden accept="image/*" />
    </div>
  );
};
